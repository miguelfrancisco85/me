---
layout: post
title: k3s
tags:
- Kubernetes
- Lightweight Kubernetes
- IoT
- Edge Computing
---
# k3s: A Lightweight Kubernetes Distribution

## What is k3s?

**k3s** is a lightweight Kubernetes distribution developed by Rancher Labs. It is designed for resource-constrained environments like IoT devices, home labs, or small-scale deployments. This document covers its key features and installation steps on both Raspberry Pi and multi-node clusters.

## Key Features of k3s

* **Lightweight:** Smaller footprint and fewer system resources than standard Kubernetes.
* **Simplified Deployment:** Runs as a single binary, reducing complexity.
* **Built-in SQLite or etcd:** Simplifies setup by eliminating external dependencies.
* **IoT & Edge Compatibility:** Works well on Raspberry Pi and ARM architectures.
* **Helm Support:** Allows easy application deployment.

## Installing k3s on Raspberry Pi

### Step 1: Prepare the Raspberry Pi

Ensure your system is up to date:

```bash
sudo apt-get update && sudo apt-get upgrade -y
```

### Step 2: Install k3s

```bash
curl -sfL https://get.k3s.io | sh -
```

This installs k3s as a service and sets up a single-node cluster.

### Step 3: Verify Installation

```bash
sudo kubectl get nodes
```

Your Raspberry Pi should be listed as  **Ready** .

### Step 4: Deploy a Test Application

```bash
kubectl create deployment nginx-test --image=nginx
kubectl expose deployment nginx-test --type=NodePort --port=80
```

Access nginx via your Raspberry Piâ€™s IP address.

## Setting Up a Multi-Node k3s Cluster

### Step 1: Install the k3s Server (Control Plane)

```bash
curl -sfL https://get.k3s.io | sh -
```

Retrieve the token for joining worker nodes:

```bash
cat /var/lib/rancher/k3s/server/node-token
```

### Step 2: Join Worker Nodes

```bash
curl -sfL https://get.k3s.io | K3S_URL="https://YOUR_K3S_SERVER_IP:6443" K3S_TOKEN="YOUR_NODE_TOKEN" sh -
```

Replace the placeholders with the actual server IP and token.

### Step 3: Verify Cluster Status

```bash
kubectl get nodes
```

All nodes should appear with the status  **Ready** .

### Step 4: Deploy Applications

Use `kubectl` or **Helm** to deploy applications.

## Example Deployment Manifest

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-k3s
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hello-k3s
  template:
    metadata:
      labels:
        app: hello-k3s
    spec:
      containers:
      - name: hello-k3s
        image: nginx
        ports:
        - containerPort: 80
```

### Apply Deployment

```bash
kubectl apply -f deployment.yaml
```

### Expose Service

```bash
kubectl expose deployment hello-k3s --type=NodePort --port=80
```

## Conclusion

k3s makes it easier to deploy Kubernetes in constrained environments while retaining compatibility with standard Kubernetes features. By following these steps, you can set up a k3s cluster for learning, development, or small-scale production use.
